# Безопасность и мониторинг Kafka

## Безопасность Apache Kafka

### Введение в безопасность Kafka

Безопасность в Kafka охватывает несколько аспектов:
- **Encryption** (шифрование): защита данных в пути и на диске
- **Authentication** (аутентификация): проверка подлинности клиентов и брокеров
- **Authorization** (авторизация): контроль доступа к ресурсам
- **Audit** (аудит): логирование доступа и операций

## Authentication (Аутентификация)

### SSL/TLS

Использование SSL/TLS для аутентификации и шифрования.

**Конфигурация брокера**
```properties
# server.properties

# SSL listeners
listeners=SSL://kafka-broker:9093
advertised.listeners=SSL://kafka-broker:9093

# Keystore (сертификат брокера)
ssl.keystore.location=/var/private/ssl/kafka.server.keystore.jks
ssl.keystore.password=server-keystore-password
ssl.key.password=server-key-password

# Truststore (доверенные CA)
ssl.truststore.location=/var/private/ssl/kafka.server.truststore.jks
ssl.truststore.password=server-truststore-password

# Client authentication
ssl.client.auth=required  # или 'requested', 'none'

# Поддерживаемые протоколы
ssl.enabled.protocols=TLSv1.2,TLSv1.3
ssl.protocol=TLSv1.3

# Cipher suites
ssl.cipher.suites=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
```

**Конфигурация клиента (Producer/Consumer)**
```properties
# producer.properties / consumer.properties

bootstrap.servers=kafka-broker:9093
security.protocol=SSL

# Client keystore
ssl.keystore.location=/var/private/ssl/kafka.client.keystore.jks
ssl.keystore.password=client-keystore-password
ssl.key.password=client-key-password

# Truststore
ssl.truststore.location=/var/private/ssl/kafka.client.truststore.jks
ssl.truststore.password=client-truststore-password

# Hostname verification
ssl.endpoint.identification.algorithm=https
```

**Java код**
```java
Properties props = new Properties();
props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "kafka-broker:9093");
props.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, "SSL");
props.put(SslConfigs.SSL_KEYSTORE_LOCATION_CONFIG, "/path/to/client.keystore.jks");
props.put(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG, "keystore-password");
props.put(SslConfigs.SSL_KEY_PASSWORD_CONFIG, "key-password");
props.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, "/path/to/client.truststore.jks");
props.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, "truststore-password");
```

### SASL (Simple Authentication and Security Layer)

#### SASL/PLAIN

Простая аутентификация с username/password.

**Конфигурация брокера**
```properties
# server.properties

listeners=SASL_SSL://kafka-broker:9093
advertised.listeners=SASL_SSL://kafka-broker:9093

security.inter.broker.protocol=SASL_SSL
sasl.mechanism.inter.broker.protocol=PLAIN
sasl.enabled.mechanisms=PLAIN

# Listener configuration
listener.name.sasl_ssl.plain.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
   username="admin" \
   password="admin-secret" \
   user_admin="admin-secret" \
   user_alice="alice-secret" \
   user_bob="bob-secret";
```

**JAAS файл для брокера** (`kafka_server_jaas.conf`)
```
KafkaServer {
   org.apache.kafka.common.security.plain.PlainLoginModule required
   username="admin"
   password="admin-secret"
   user_admin="admin-secret"
   user_alice="alice-secret"
   user_bob="bob-secret";
};
```

**Запуск брокера с JAAS**
```bash
export KAFKA_OPTS="-Djava.security.auth.login.config=/etc/kafka/kafka_server_jaas.conf"
kafka-server-start.sh server.properties
```

**Конфигурация клиента**
```properties
# producer.properties

bootstrap.servers=kafka-broker:9093
security.protocol=SASL_SSL
sasl.mechanism=PLAIN
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
   username="alice" \
   password="alice-secret";
```

#### SASL/SCRAM

SCRAM (Salted Challenge Response Authentication Mechanism) - более безопасная альтернатива PLAIN.

**Создание учетных записей**
```bash
# SCRAM-SHA-256
kafka-configs.sh --bootstrap-server localhost:9092 \
  --alter \
  --add-config 'SCRAM-SHA-256=[password=alice-secret],SCRAM-SHA-512=[password=alice-secret]' \
  --entity-type users \
  --entity-name alice

# Список пользователей
kafka-configs.sh --bootstrap-server localhost:9092 \
  --describe \
  --entity-type users
```

**Конфигурация брокера**
```properties
# server.properties

listeners=SASL_SSL://kafka-broker:9093
sasl.enabled.mechanisms=SCRAM-SHA-256,SCRAM-SHA-512

listener.name.sasl_ssl.scram-sha-256.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
   username="admin" \
   password="admin-secret";
```

**Конфигурация клиента**
```properties
security.protocol=SASL_SSL
sasl.mechanism=SCRAM-SHA-256
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
   username="alice" \
   password="alice-secret";
```

#### SASL/GSSAPI (Kerberos)

Enterprise аутентификация через Kerberos.

**Конфигурация брокера**
```properties
# server.properties

listeners=SASL_SSL://kafka-broker:9093
sasl.enabled.mechanisms=GSSAPI
sasl.kerberos.service.name=kafka
```

**JAAS файл** (`kafka_server_jaas.conf`)
```
KafkaServer {
   com.sun.security.auth.module.Krb5LoginModule required
   useKeyTab=true
   storeKey=true
   keyTab="/etc/security/keytabs/kafka_server.keytab"
   principal="kafka/kafka-broker@REALM.COM";
};
```

**Конфигурация клиента**
```properties
security.protocol=SASL_SSL
sasl.mechanism=GSSAPI
sasl.kerberos.service.name=kafka
sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required \
   useKeyTab=true \
   storeKey=true \
   keyTab="/etc/security/keytabs/alice.keytab" \
   principal="alice@REALM.COM";
```

#### SASL/OAUTHBEARER

OAuth 2.0 аутентификация.

**Конфигурация брокера**
```properties
listeners=SASL_SSL://kafka-broker:9093
sasl.enabled.mechanisms=OAUTHBEARER
```

**JAAS конфигурация**
```
KafkaServer {
  org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required
  unsecuredLoginStringClaim_sub="admin";
};
```

**Конфигурация клиента**
```java
props.put("sasl.mechanism", "OAUTHBEARER");
props.put("sasl.jaas.config", 
    "org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required;");
props.put("sasl.login.callback.handler.class", 
    "com.example.CustomOAuthBearerHandler");
```

## Authorization (Авторизация)

### ACL (Access Control Lists)

Kafka использует ACL для контроля доступа к ресурсам.

**Включение ACL**
```properties
# server.properties

# Authorizer
authorizer.class.name=kafka.security.authorizer.AclAuthorizer

# Super users (не проверяются ACL)
super.users=User:admin;User:kafka

# По умолчанию запретить всё
allow.everyone.if.no.acl.found=false
```

**Типы ресурсов**
- Topic
- Group (consumer groups)
- Cluster
- TransactionalId
- DelegationToken

**Операции**
- Read
- Write
- Create
- Delete
- Alter
- Describe
- ClusterAction
- DescribeConfigs
- AlterConfigs
- IdempotentWrite
- All

**Управление ACL**

```bash
# Разрешить alice читать из топика orders
kafka-acls.sh --bootstrap-server localhost:9093 \
  --command-config admin.properties \
  --add \
  --allow-principal User:alice \
  --operation Read \
  --topic orders

# Разрешить alice писать в топик orders
kafka-acls.sh --bootstrap-server localhost:9093 \
  --command-config admin.properties \
  --add \
  --allow-principal User:alice \
  --operation Write \
  --topic orders

# Разрешить alice использовать consumer group
kafka-acls.sh --bootstrap-server localhost:9093 \
  --command-config admin.properties \
  --add \
  --allow-principal User:alice \
  --operation Read \
  --group order-consumers

# Разрешить все операции на топике
kafka-acls.sh --bootstrap-server localhost:9093 \
  --command-config admin.properties \
  --add \
  --allow-principal User:bob \
  --operation All \
  --topic test-topic

# Разрешить создание топиков
kafka-acls.sh --bootstrap-server localhost:9093 \
  --command-config admin.properties \
  --add \
  --allow-principal User:bob \
  --operation Create \
  --cluster

# Wildcard для всех топиков с префиксом
kafka-acls.sh --bootstrap-server localhost:9093 \
  --command-config admin.properties \
  --add \
  --allow-principal User:alice \
  --operation Read \
  --topic "dev-*" \
  --resource-pattern-type prefixed

# Просмотр ACL
kafka-acls.sh --bootstrap-server localhost:9093 \
  --command-config admin.properties \
  --list

# Просмотр ACL для конкретного топика
kafka-acls.sh --bootstrap-server localhost:9093 \
  --command-config admin.properties \
  --list \
  --topic orders

# Удаление ACL
kafka-acls.sh --bootstrap-server localhost:9093 \
  --command-config admin.properties \
  --remove \
  --allow-principal User:alice \
  --operation Read \
  --topic orders
```

**Примеры типичных ACL**

Producer ACL:
```bash
# Write к топику
kafka-acls.sh --add --allow-principal User:producer-app \
  --operation Write --topic orders

# Describe топика
kafka-acls.sh --add --allow-principal User:producer-app \
  --operation Describe --topic orders

# IdempotentWrite для exactly-once
kafka-acls.sh --add --allow-principal User:producer-app \
  --operation IdempotentWrite --cluster
```

Consumer ACL:
```bash
# Read из топика
kafka-acls.sh --add --allow-principal User:consumer-app \
  --operation Read --topic orders

# Describe топика
kafka-acls.sh --add --allow-principal User:consumer-app \
  --operation Describe --topic orders

# Read consumer group
kafka-acls.sh --add --allow-principal User:consumer-app \
  --operation Read --group order-consumers
```

### Kafka Connect ACL

```bash
# Source Connector
kafka-acls.sh --add --allow-principal User:connect-worker \
  --operation Write --topic source-topic
kafka-acls.sh --add --allow-principal User:connect-worker \
  --operation Create --cluster

# Sink Connector
kafka-acls.sh --add --allow-principal User:connect-worker \
  --operation Read --topic sink-topic
kafka-acls.sh --add --allow-principal User:connect-worker \
  --operation Read --group connect-sink-group
```

## Encryption (Шифрование)

### Encryption in Transit (SSL/TLS)

Уже описано в разделе SSL/TLS выше.

### Encryption at Rest

Kafka не предоставляет встроенное шифрование на диске, но можно использовать:

**Filesystem-level encryption**
- LUKS (Linux Unified Key Setup)
- dm-crypt
- eCryptfs

**Cloud provider encryption**
- AWS EBS encryption
- Azure Disk Encryption
- GCP persistent disk encryption

**Пример с LUKS**
```bash
# Создание зашифрованного раздела
cryptsetup luksFormat /dev/sdb
cryptsetup luksOpen /dev/sdb kafka_encrypted
mkfs.ext4 /dev/mapper/kafka_encrypted
mount /dev/mapper/kafka_encrypted /var/lib/kafka
```

## Мониторинг Apache Kafka

### JMX Метрики

#### Broker Metrics

**Throughput**
```
kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec
kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec
kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec
```

**Request Metrics**
```
kafka.network:type=RequestMetrics,name=RequestsPerSec,request={Produce|Fetch}
kafka.network:type=RequestMetrics,name=TotalTimeMs,request={Produce|Fetch}
kafka.network:type=RequestMetrics,name=RequestQueueTimeMs,request={Produce|Fetch}
```

**Partition Metrics**
```
kafka.cluster:type=Partition,name=UnderReplicated
kafka.server:type=ReplicaManager,name=LeaderCount
kafka.server:type=ReplicaManager,name=PartitionCount
kafka.server:type=ReplicaManager,name=IsrShrinksPerSec
kafka.server:type=ReplicaManager,name=IsrExpandsPerSec
```

**Log Metrics**
```
kafka.log:type=Log,name=Size,topic=*,partition=*
kafka.log:type=LogFlushStats,name=LogFlushRateAndTimeMs
```

#### Producer Metrics

```
kafka.producer:type=producer-metrics,client-id=*
  - record-send-rate
  - record-error-rate
  - request-latency-avg
  - batch-size-avg
  - compression-rate-avg
```

#### Consumer Metrics

```
kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*
  - records-consumed-rate
  - bytes-consumed-rate
  - records-lag-max
  - fetch-latency-avg
  
kafka.consumer:type=consumer-coordinator-metrics,client-id=*
  - commit-latency-avg
  - assigned-partitions
```

### Prometheus Integration

**JMX Exporter конфигурация**

```yaml
# jmx_exporter.yml
lowercaseOutputName: true
lowercaseOutputLabelNames: true

rules:
  # Broker metrics
  - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
    name: kafka_server_$1_$2
    type: GAUGE
    labels:
      clientId: "$3"
      topic: "$4"
      partition: "$5"
      
  # Producer metrics
  - pattern: kafka.producer<type=(.+), client-id=(.+)><>(.+-total|.+-avg|.+-rate)
    name: kafka_producer_$1_$3
    type: GAUGE
    labels:
      client_id: "$2"
      
  # Consumer metrics
  - pattern: kafka.consumer<type=(.+), client-id=(.+)><>(.+-total|.+-avg|.+-rate|.+-max)
    name: kafka_consumer_$1_$3
    type: GAUGE
    labels:
      client_id: "$2"
```

**Запуск с JMX Exporter**
```bash
export KAFKA_OPTS="-javaagent:/opt/jmx_exporter/jmx_prometheus_javaagent.jar=7071:/etc/kafka/jmx_exporter.yml"
kafka-server-start.sh server.properties
```

**Prometheus scrape config**
```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'kafka-broker'
    static_configs:
      - targets: ['kafka-broker-1:7071', 'kafka-broker-2:7071', 'kafka-broker-3:7071']
        labels:
          env: 'production'
```

### Grafana Dashboards

Популярные метрики для дашбордов:

**Cluster Health**
- Under-replicated partitions
- Offline partitions
- Active controllers
- Broker up/down status

**Throughput**
- Messages in per second (по топикам)
- Bytes in/out per second
- Request rate (Produce/Fetch)

**Latency**
- Producer latency (p99, p95, avg)
- Consumer lag (max, avg)
- Request time (p99, p95)

**Resource Usage**
- CPU usage
- Memory usage
- Disk I/O
- Network I/O

### Kafka Manager / AKHQ / Confluent Control Center

**AKHQ (Kafka HQ)**
- Web UI для управления Kafka
- Просмотр топиков, consumer groups, ACL
- Мониторинг lag, throughput
- Создание/удаление топиков

**Docker Compose пример**
```yaml
version: '3'
services:
  akhq:
    image: tchiotludo/akhq:latest
    ports:
      - "8080:8080"
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            production:
              properties:
                bootstrap.servers: "kafka:9092"
              schema-registry:
                url: "http://schema-registry:8081"
              connect:
                - name: "connect"
                  url: "http://kafka-connect:8083"
```

### Logging

**log4j configuration**
```properties
# log4j.properties

log4j.rootLogger=INFO, stdout, kafkaAppender

log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n

# Kafka logs
log4j.appender.kafkaAppender=org.apache.log4j.DailyRollingFileAppender
log4j.appender.kafkaAppender.DatePattern='.'yyyy-MM-dd-HH
log4j.appender.kafkaAppender.File=${kafka.logs.dir}/server.log
log4j.appender.kafkaAppender.layout=org.apache.log4j.PatternLayout
log4j.appender.kafkaAppender.layout.ConversionPattern=[%d] %p %m (%c)%n

# Request logs
log4j.logger.kafka.request.logger=WARN, requestAppender
log4j.additivity.kafka.request.logger=false

log4j.appender.requestAppender=org.apache.log4j.DailyRollingFileAppender
log4j.appender.requestAppender.DatePattern='.'yyyy-MM-dd-HH
log4j.appender.requestAppender.File=${kafka.logs.dir}/kafka-request.log
log4j.appender.requestAppender.layout=org.apache.log4j.PatternLayout
log4j.appender.requestAppender.layout.ConversionPattern=[%d] %p %m (%c)%n
```

### Alerting

**Prometheus Alerting Rules**
```yaml
# alerts.yml
groups:
  - name: kafka
    interval: 30s
    rules:
      # Under-replicated partitions
      - alert: KafkaUnderReplicatedPartitions
        expr: kafka_server_replicamanager_underreplicatedpartitions > 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Kafka has under-replicated partitions"
          
      # Offline partitions
      - alert: KafkaOfflinePartitions
        expr: kafka_controller_kafkacontroller_offlinepartitionscount > 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Kafka has offline partitions"
          
      # Consumer lag
      - alert: KafkaConsumerLagHigh
        expr: kafka_consumer_fetch_manager_records_lag_max > 1000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Consumer lag is high (> 1000 messages)"
          
      # No active controller
      - alert: KafkaNoActiveController
        expr: sum(kafka_controller_kafkacontroller_activecontrollercount) != 1
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "No active Kafka controller"
          
      # Broker down
      - alert: KafkaBrokerDown
        expr: up{job="kafka-broker"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Kafka broker is down"
```

## Best Practices

### Безопасность

1. **Всегда используйте SSL/TLS в production**
2. **Используйте SCRAM вместо PLAIN**
3. **Принцип наименьших привилегий для ACL**
4. **Регулярно ротируйте credentials**
5. **Мониторьте authentication failures**
6. **Используйте network segmentation**
7. **Включите audit logging**
8. **Шифруйте диски в cloud окружениях**

### Мониторинг

1. **Мониторьте under-replicated partitions**
2. **Алерты на offline partitions**
3. **Отслеживайте consumer lag**
4. **Мониторьте disk usage**
5. **Следите за ISR shrinks/expands**
6. **Мониторьте request latency (p99)**
7. **Алерты на no active controller**
8. **Capacity planning по метрикам роста**

## Вопросы для самопроверки

1. **Какие механизмы аутентификации поддерживает Kafka?**
   - SSL/TLS, SASL/PLAIN, SASL/SCRAM, SASL/GSSAPI (Kerberos), SASL/OAUTHBEARER

2. **В чем разница между SASL/PLAIN и SASL/SCRAM?**
   - SCRAM более безопасен (salted hashes), PLAIN передает пароль в открытом виде

3. **Что такое ACL в Kafka?**
   - Access Control Lists для авторизации доступа к ресурсам (topics, groups, cluster)

4. **Какие метрики критичны для мониторинга Kafka?**
   - Under-replicated partitions, offline partitions, consumer lag, ISR changes

5. **Как включить шифрование данных в Kafka?**
   - SSL/TLS для encryption in transit, filesystem/disk encryption для at rest

6. **Что такое super.users?**
   - Пользователи, которые не проверяются ACL (полный доступ ко всему)

7. **Как мониторить consumer lag?**
   - JMX метрика records-lag-max, или kafka-consumer-groups.sh --describe

8. **Какие операции требуют IdempotentWrite?**
   - Idempotent producers и transactional producers

9. **Как обеспечить безопасность в multi-tenant окружении?**
   - ACL для изоляции, quota для ресурсов, отдельные topics per tenant

10. **Что делать если много under-replicated partitions?**
    - Проверить сеть, disk I/O, добавить capacity, проверить broker health
